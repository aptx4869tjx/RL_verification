ssh://TianJiaXu@219.228.60.69:22/home/TianJiaXu/anaconda3/envs/rlpy37/bin/python3.7 -u /home/TianJiaXu/RL2/verify/cartpole/cart_example.py
2022-05-16-23_34_23
number of states in rtree 3180
2022-05-16-23_34_23
2022-05-16-23_34_23
episode= 50
avg reward: 34.88
episode= 100
avg reward: 31.82
episode= 150
avg reward: 36.1
episode= 200
avg reward: 13.58
episode= 250
avg reward: 20.56
episode= 300
avg reward: 232.6
episode= 350
avg reward: 259.84
episode= 400
avg reward: 392.5
episode= 450
avg reward: 465.82
episode= 500
avg reward: 290.98
episode= 550
avg reward: 500.0
episode= 600
avg reward: 500.0
episode= 650
avg reward: 437.76
episode= 700
avg reward: 318.5
episode= 750
avg reward: 401.06
episode= 800
avg reward: 500.0
episode= 850
avg reward: 500.0
episode= 900
avg reward: 476.06
episode= 950
avg reward: 432.74
episode= 1000
avg reward: 495.5
episode= 1050
avg reward: 204.26
episode= 1100
avg reward: 460.12
episode= 1150
avg reward: 487.62
episode= 1200
avg reward: 413.68
episode= 1250
avg reward: 350.68
episode= 1300
avg reward: 403.06
episode= 1350
avg reward: 332.66
episode= 1400
avg reward: 285.24
episode= 1450
avg reward: 381.86
episode= 1500
avg reward: 393.08
episode= 1550
avg reward: 494.96
episode= 1600
avg reward: 399.86
episode= 1650
avg reward: 297.24
episode= 1700
avg reward: 313.86
episode= 1750
avg reward: 240.74
episode= 1800
avg reward: 464.18
episode= 1850
avg reward: 352.22
episode= 1900
avg reward: 397.54
episode= 1950
avg reward: 430.94
episode= 2000
avg reward: 497.7
episode= 2050
avg reward: 426.78
episode= 2100
avg reward: 489.5
episode= 2150
avg reward: 288.84
episode= 2200
avg reward: 482.44
episode= 2250
avg reward: 366.74
episode= 2300
avg reward: 489.58
episode= 2350
avg reward: 426.32
episode= 2400
avg reward: 399.74
episode= 2450
avg reward: 424.08
episode= 2500
avg reward: 410.46
episode= 2550
avg reward: 465.44
episode= 2600
avg reward: 270.36
episode= 2650
avg reward: 424.88
episode= 2700
avg reward: 340.88
episode= 2750
avg reward: 417.42
episode= 2800
avg reward: 362.82
episode= 2850
avg reward: 373.78
episode= 2900
avg reward: 398.18
episode= 2950
avg reward: 480.2
episode= 3000
avg reward: 360.34
episode= 3050
avg reward: 392.24
episode= 3100
avg reward: 464.76
episode= 3150
avg reward: 378.2
episode= 3200
avg reward: 462.32
episode= 3250
avg reward: 418.42
episode= 3300
avg reward: 330.6
episode= 3350
avg reward: 109.7
episode= 3400
avg reward: 207.66
episode= 3450
avg reward: 377.88
episode= 3500
avg reward: 296.82
episode= 3550
avg reward: 245.06
episode= 3600
avg reward: 358.84
episode= 3650
avg reward: 437.0
episode= 3700
avg reward: 327.52
episode= 3750
avg reward: 397.58
episode= 3800
avg reward: 246.34
episode= 3850
avg reward: 250.02
episode= 3900
avg reward: 424.84
episode= 3950
avg reward: 283.74
episode= 4000
avg reward: 251.52
episode= 4050
avg reward: 230.38
episode= 4100
avg reward: 106.1
episode= 4150
avg reward: 243.04
episode= 4200
avg reward: 160.7
episode= 4250
avg reward: 133.82
episode= 4300
avg reward: 130.54
episode= 4350
avg reward: 118.6
episode= 4400
avg reward: 103.78
episode= 4450
avg reward: 95.4
episode= 4500
avg reward: 91.04
episode= 4550
avg reward: 87.24
episode= 4600
avg reward: 85.66
episode= 4650
avg reward: 90.0
episode= 4700
avg reward: 94.94
episode= 4750
avg reward: 100.78
episode= 4800
avg reward: 97.8
episode= 4850
avg reward: 93.72
episode= 4900
avg reward: 97.22
episode= 4950
avg reward: 93.58
episode= 5000
avg reward: 93.2
/home/TianJiaXu/RL2/abstract/cartpole/dqn0.pt loaded.
number of initial states: 1
9 37 depth 0 0.0012226104736328125   0.0010159015655517578 increase 8
16 205 depth 1 0.02040266990661621   0.017494678497314453 increase 7
25 789 depth 2 0.09348702430725098   0.08055973052978516 increase 9
40 2626 depth 3 0.3266031742095947   0.28200411796569824 increase 15
56 7129 depth 4 1.0616438388824463   0.9180514812469482 increase 16
79 15196 depth 5 2.502284288406372   2.1698098182678223 increase 23
111 28438 depth 6 4.744617223739624   4.095702409744263 increase 32
137 49968 depth 7 7.382663726806641   6.390691757202148 increase 26
178 84294 depth 8 12.578882694244385   10.856707096099854 increase 41
224 134477 depth 9 19.505743265151978   16.867746353149414 increase 46
270 207581 depth 10 27.890942811965942   24.09692358970642 increase 46
317 306553 depth 11 39.80323910713196   34.38412809371948 increase 47
360 428784 depth 12 51.41322135925293   44.367451429367065 increase 43
399 566747 depth 13 59.18131899833679   51.06783890724182 increase 39
441 718383 depth 14 66.76791167259216   57.55822491645813 increase 42
482 879921 depth 15 73.87600827217102   63.79643654823303 increase 41
520 1055198 depth 16 79.35300946235657   68.48020076751709 increase 38
562 1245031 depth 17 87.13560032844543   75.28649234771729 increase 42
600 1453223 depth 18 95.8599328994751   82.76339507102966 increase 38
628 1681903 depth 19 106.26725435256958   91.8138177394867 increase 28
645 1914386 depth 20 108.80809760093689   93.89427661895752 increase 17
664 2155992 depth 21 111.7078549861908   96.35946917533875 increase 19
682 2416396 depth 22 117.53541207313538   101.4485695362091 increase 18
704 2707304 depth 23 129.2836549282074   111.54804182052612 increase 22
725 3021737 depth 24 140.34114289283752   121.13697552680969 increase 21
738 3342796 depth 25 148.21171259880066   127.68686652183533 increase 13
755 3670488 depth 26 153.54896211624146   132.3660535812378 increase 17
772 4018811 depth 27 159.1587929725647   137.32772040367126 increase 17
786 4399013 depth 28 171.55184173583984   148.16503524780273 increase 14
797 4806335 depth 29 181.7118957042694   156.68242740631104 increase 11
814 5238930 depth 30 191.3136489391327   164.90430688858032 increase 17
823 5693274 depth 31 200.2351438999176   172.50313687324524 increase 9
833 6144769 depth 32 200.73172116279602   172.74030661582947 increase 10
839 6592698 depth 33 199.74286484718323   171.91122221946716 increase 6
842 7033975 depth 34 197.41762781143188   169.9712290763855 increase 3
848 7468880 depth 35 195.9705204963684   168.6176598072052 increase 6
851 7898133 depth 36 193.76586961746216   166.75873398780823 increase 3
855 8313980 depth 37 188.7385172843933   162.35829091072083 increase 4
859 8726933 depth 38 186.76216053962708   160.811936378479 increase 4
860 9130700 depth 39 182.27486968040466   156.85870027542114 increase 1
862 9524007 depth 40 177.6498715877533   152.77743339538574 increase 2
864 9911940 depth 41 173.77641582489014   149.52755737304688 increase 2
867 10284028 depth 42 167.30138683319092   143.65383553504944 increase 3
869 10652759 depth 43 165.33832097053528   142.36797547340393 increase 2
871 11008656 depth 44 159.44196915626526   137.05772733688354 increase 2
871 11351222 depth 45 153.23504853248596   131.7552170753479 increase 0
873 11693234 depth 46 156.5584259033203   134.60066723823547 increase 2
874 12022033 depth 47 153.65270161628723   132.12648963928223 increase 1
875 12340599 depth 48 150.16376328468323   129.09745573997498 increase 1
876 12652839 depth 49 143.46937441825867   123.39036846160889 increase 1
final_state_count:  876
{'safe'}
1 not(A(G(safe)))
CTL formula satisfied: not(A(G(safe))) 1 0
number of counterexamplesï¼š 875
train time: 942.3952841758728 construct kripke structure: 5696.297342300415 model checking: 0.041170358657836914
2022-05-17-01_25_01
2022-05-17-01_25_01
[-4.8, -0.42, 4.8, 0.428]
number of all states in rtree 3180
--------- 875 2305 3500
number of states after refinement: 5805
2022-05-17-01_25_02
episode= 50
avg reward: 43.4
episode= 100
avg reward: 43.14
episode= 150
avg reward: 20.84
episode= 200
avg reward: 14.3
episode= 250
avg reward: 141.94
episode= 300
avg reward: 395.92
episode= 350
avg reward: 494.2
episode= 400
avg reward: 300.6
episode= 450
avg reward: 428.66
episode= 500
avg reward: 474.42
episode= 550
avg reward: 473.82
episode= 600
avg reward: 396.98
episode= 650
avg reward: 406.02
episode= 700
avg reward: 413.84
episode= 750
avg reward: 386.04
episode= 800
avg reward: 303.76
episode= 850
avg reward: 410.04
episode= 900
avg reward: 380.5
episode= 950
avg reward: 386.62
episode= 1000
avg reward: 355.4
episode= 1050
avg reward: 178.36
episode= 1100
avg reward: 248.74
episode= 1150
avg reward: 456.56
episode= 1200
avg reward: 455.16
episode= 1250
avg reward: 401.82
episode= 1300
avg reward: 305.48
episode= 1350
avg reward: 437.1
episode= 1400
avg reward: 497.62
episode= 1450
avg reward: 437.44
episode= 1500
avg reward: 406.58
episode= 1550
avg reward: 365.98
episode= 1600
avg reward: 424.1
episode= 1650
avg reward: 417.04
episode= 1700
avg reward: 434.18
episode= 1750
avg reward: 493.44
episode= 1800
avg reward: 357.76
episode= 1850
avg reward: 374.62
episode= 1900
avg reward: 410.48
episode= 1950
avg reward: 500.0
0   evaluate total_reward 1000.0 0.12008927011608024 0.03425541744834136 1000
1   evaluate total_reward 1000.0 0.3192431865019791 0.037686967822951355 1000
2   evaluate total_reward 1000.0 0.1778436828690188 0.03985687042897881 1000
3   evaluate total_reward 1000.0 0.31431719495451743 0.04181353527756369 1000
4   evaluate total_reward 1000.0 0.1028790693906034 0.023518675015730968 1000
5   evaluate total_reward 1000.0 0.11897040047443092 0.03109081447190264 1000
6   evaluate total_reward 1000.0 0.11082844764075656 0.03657173240470298 1000
7   evaluate total_reward 1000.0 0.2691391108267499 0.03933162481815396 1000
8   evaluate total_reward 1000.0 0.33426396529651736 0.03921367058470569 1000
9   evaluate total_reward 1000.0 0.12809630151585064 0.03891946353956793 1000
training finished, episode= 1950
/home/TianJiaXu/RL2/abstract/cartpole/dqn0.pt loaded.
number of initial states: 1
9 37 depth 0 0.0009763240814208984   0.0007691383361816406 increase 8
16 225 depth 1 0.019278287887573242   0.01666259765625 increase 7
36 1035 depth 2 0.11969113349914551   0.10278511047363281 increase 20
56 2890 depth 3 0.4291050434112549   0.3742833137512207 increase 20
86 6748 depth 4 1.0864691734313965   0.9388952255249023 increase 30
115 13995 depth 5 2.060417652130127   1.7904019355773926 increase 29
155 26646 depth 6 4.077860116958618   3.533738136291504 increase 40
200 46660 depth 7 6.910298109054565   6.008495092391968 increase 45
247 77314 depth 8 11.164113283157349   9.689674854278564 increase 47
280 122020 depth 9 16.74656915664673   14.556262493133545 increase 33
327 182757 depth 10 24.659107446670532   21.416157960891724 increase 47
382 265531 depth 11 33.200300455093384   28.834304571151733 increase 55
440 374159 depth 12 45.33893537521362   39.375975131988525 increase 58
497 511177 depth 13 58.98462891578674   51.27033615112305 increase 57
582 680154 depth 14 74.93616724014282   65.07723069190979 increase 85
674 882604 depth 15 91.51062393188477   79.5823392868042 increase 92
767 1119134 depth 16 110.85308027267456   96.30126857757568 increase 93
837 1388069 depth 17 128.5285427570343   111.64481711387634 increase 70
918 1690399 depth 18 147.4720973968506   128.0920295715332 increase 81
985 2026532 depth 19 166.64423942565918   144.6206192970276 increase 67
1078 2390257 depth 20 182.77782464027405   158.7785120010376 increase 93
1170 2778424 depth 21 200.19555115699768   173.77064728736877 increase 92
1251 3183980 depth 22 211.6130404472351   183.83781337738037 increase 81
1303 3595316 depth 23 219.56564044952393   190.655992269516 increase 52
1355 4004729 depth 24 220.1630859375   191.14211583137512 increase 52
1416 4423127 depth 25 221.70433640480042   192.47865557670593 increase 61
1476 4862256 depth 26 227.64537930488586   197.71958875656128 increase 60
1532 5320389 depth 27 240.84436774253845   209.06152415275574 increase 56
1574 5780487 depth 28 250.90780591964722   217.7979485988617 increase 42
1618 6240370 depth 29 251.72276329994202   218.39315247535706 increase 44
1666 6700385 depth 30 249.50840139389038   216.76641154289246 increase 48
1696 7161013 depth 31 247.04507112503052   214.37338185310364 increase 30
1730 7629998 depth 32 248.11525583267212   215.31990671157837 increase 34
1774 8112611 depth 33 253.46390795707703   219.71761417388916 increase 44
1810 8602980 depth 34 257.98320841789246   223.78032279014587 increase 36
1855 9114732 depth 35 265.17148900032043   229.8615026473999 increase 45
1884 9641293 depth 36 275.75270915031433   239.18765497207642 increase 29
1934 10186535 depth 37 283.8756594657898   245.82343983650208 increase 50
1969 10745518 depth 38 295.1179847717285   255.88129448890686 increase 35
2011 11316188 depth 39 301.51541447639465   261.5283396244049 increase 42
2032 11900816 depth 40 308.63764786720276   267.6482274532318 increase 21
2049 12493511 depth 41 314.30550742149353   272.6956293582916 increase 17
2070 13095465 depth 42 317.6964497566223   275.47204065322876 increase 21
2089 13713672 depth 43 326.1617832183838   283.10461831092834 increase 19
2104 14346082 depth 44 335.09770154953003   290.74222207069397 increase 15
2128 14981106 depth 45 339.1835458278656   294.3330428600311 increase 24
2143 15614837 depth 46 337.1246762275696   292.4603214263916 increase 15
2153 16246229 depth 47 337.6093809604645   293.1588704586029 increase 10
2177 16874008 depth 48 336.4879240989685   292.07036328315735 increase 24
2208 17498378 depth 49 332.5027644634247   288.51991271972656 increase 31
final_state_count:  2208
{'safe'}
1 not(A(G(safe)))
CTL formula satisfied: not(A(G(safe))) 1 0
number of counterexamplesï¼š 2174
iteration : 1 True 2174
refine: 0.2535228729248047 train: 405.61173820495605 construct kripke structure: 9115.910542011261 model checking: 0.12077808380126953
2022-05-17-04_03_43
2022-05-17-04_03_43
[-4.8, -0.42, 4.8, 0.428]
number of all states in rtree 5805
cnt1 1000
cnt1 2000
--------- 2174 3631 8696
number of states after refinement: 12327
2022-05-17-04_03_44
episode= 50
avg reward: 10.14
episode= 100
avg reward: 9.56
episode= 150
avg reward: 9.68
episode= 200
avg reward: 9.84
episode= 250
avg reward: 9.66
episode= 300
avg reward: 9.54
episode= 350
avg reward: 10.16
episode= 400
avg reward: 9.7
episode= 450
avg reward: 9.58
episode= 500
avg reward: 9.68
episode= 550
avg reward: 9.5
episode= 600
avg reward: 10.04
episode= 650
avg reward: 9.46
episode= 700
avg reward: 65.16
episode= 750
avg reward: 54.22
episode= 800
avg reward: 245.24
episode= 850
avg reward: 196.12
episode= 900
avg reward: 9.3
episode= 950
avg reward: 181.86
episode= 1000
avg reward: 111.78
episode= 1050
avg reward: 59.0
episode= 1100
avg reward: 46.28
episode= 1150
avg reward: 41.68
episode= 1200
avg reward: 37.42
episode= 1250
avg reward: 32.82
episode= 1300
avg reward: 30.4
episode= 1350
avg reward: 27.52
episode= 1400
avg reward: 25.72
episode= 1450
avg reward: 25.02
episode= 1500
avg reward: 24.68
episode= 1550
avg reward: 22.84
episode= 1600
avg reward: 23.1
episode= 1650
avg reward: 23.48
episode= 1700
avg reward: 23.08
episode= 1750
avg reward: 22.16
episode= 1800
avg reward: 20.78
episode= 1850
avg reward: 20.84
episode= 1900
avg reward: 21.1
episode= 1950
avg reward: 18.88
episode= 2000
avg reward: 18.52
episode= 2050
avg reward: 17.98
episode= 2100
avg reward: 17.06
episode= 2150
avg reward: 15.98
episode= 2200
avg reward: 15.5
episode= 2250
avg reward: 15.84
episode= 2300
avg reward: 15.12
episode= 2350
avg reward: 15.12
episode= 2400
avg reward: 14.04
episode= 2450
avg reward: 13.84
episode= 2500
avg reward: 14.04
episode= 2550
avg reward: 14.02
episode= 2600
avg reward: 14.22
episode= 2650
avg reward: 12.66
episode= 2700
avg reward: 13.26
episode= 2750
avg reward: 12.8
episode= 2800
avg reward: 12.88
episode= 2850
avg reward: 12.32
episode= 2900
avg reward: 13.0
episode= 2950
avg reward: 12.42
episode= 3000
avg reward: 13.2
episode= 3050
avg reward: 13.12
episode= 3100
avg reward: 12.12
episode= 3150
avg reward: 12.3
episode= 3200
avg reward: 12.88
episode= 3250
avg reward: 11.8
episode= 3300
avg reward: 11.94
episode= 3350
avg reward: 12.16
episode= 3400
avg reward: 12.58
episode= 3450
avg reward: 11.98
episode= 3500
avg reward: 11.6
episode= 3550
avg reward: 11.92
episode= 3600
avg reward: 11.0
episode= 3650
avg reward: 11.88
episode= 3700
avg reward: 11.76
episode= 3750
avg reward: 11.0
episode= 3800
avg reward: 11.5
episode= 3850
avg reward: 11.26
episode= 3900
avg reward: 11.3
episode= 3950
avg reward: 10.96
episode= 4000
avg reward: 11.66
episode= 4050
avg reward: 10.84
episode= 4100
avg reward: 11.06
episode= 4150
avg reward: 10.96
episode= 4200
avg reward: 10.46
episode= 4250
avg reward: 10.98
episode= 4300
avg reward: 10.44
episode= 4350
avg reward: 10.4
episode= 4400
avg reward: 10.84
episode= 4450
avg reward: 10.8
episode= 4500
avg reward: 10.4
episode= 4550
avg reward: 10.56
episode= 4600
avg reward: 10.66
episode= 4650
avg reward: 10.52
episode= 4700
avg reward: 10.16
episode= 4750
avg reward: 10.64
episode= 4800
avg reward: 13.42
episode= 4850
avg reward: 9.36
episode= 4900
avg reward: 9.02
episode= 4950
avg reward: 9.92
episode= 5000
avg reward: 51.38
/home/TianJiaXu/RL2/abstract/cartpole/dqn0.pt loaded.
number of initial states: 1
9 37 depth 0 0.0010113716125488281   0.0008089542388916016 increase 8
19 180 depth 1 0.01935267448425293   0.016829729080200195 increase 10
36 809 depth 2 0.10539960861206055   0.09002947807312012 increase 17
68 2067 depth 3 0.3280026912689209   0.28654932975769043 increase 32
105 5314 depth 4 0.8158986568450928   0.70200514793396 increase 37
155 10244 depth 5 1.6983022689819336   1.4842536449432373 increase 50
211 19624 depth 6 2.977703809738159   2.5750949382781982 increase 56
289 34842 depth 7 5.106781482696533   4.439955949783325 increase 78
398 59719 depth 8 8.726974248886108   7.56537938117981 increase 109
537 99547 depth 9 13.862764358520508   12.043328762054443 increase 139
722 160413 depth 10 22.176206588745117   19.246934175491333 increase 185
970 254026 depth 11 33.390077114105225   28.974506378173828 increase 248
1293 394501 depth 12 51.25832533836365   44.47537899017334 increase 323
1578 588338 depth 13 75.45911622047424   65.58009886741638 increase 285
1794 826372 depth 14 99.47508811950684   86.54012942314148 increase 216
1954 1095495 depth 15 117.505042552948   102.23006010055542 increase 160
2110 1400609 depth 16 131.8385636806488   114.51265072822571 increase 156
2261 1708719 depth 17 143.82919788360596   125.05066323280334 increase 151
2419 2029212 depth 18 148.197767496109   128.68200159072876 increase 158
2558 2348218 depth 19 157.14385604858398   136.4765841960907 increase 139
2730 2669678 depth 20 157.19481873512268   136.51055788993835 increase 172
2880 2998281 depth 21 160.9625222682953   139.81706047058105 increase 150
3057 3328327 depth 22 165.50471949577332   143.83468103408813 increase 177
3209 3662843 depth 23 164.735999584198   143.14971041679382 increase 152
3385 4003949 depth 24 168.74923634529114   146.52960324287415 increase 176
3547 4347289 depth 25 171.0548768043518   148.57136750221252 increase 162
3726 4694699 depth 26 173.54068326950073   150.73869037628174 increase 179
3890 5044805 depth 27 177.06128215789795   153.6725857257843 increase 164
4075 5397390 depth 28 178.2090802192688   154.77261781692505 increase 185
4259 5756543 depth 29 182.08245420455933   158.25230407714844 increase 184
4453 6113894 depth 30 183.09034991264343   159.0693621635437 increase 194
4626 6480446 depth 31 182.24584770202637   158.25822281837463 increase 173
4818 6842010 depth 32 187.93259453773499   163.22730231285095 increase 192
4978 7211127 depth 33 185.17675185203552   160.831627368927 increase 160
5158 7573473 depth 34 187.74864101409912   163.00340270996094 increase 180
5304 7939842 depth 35 184.63640928268433   160.36041164398193 increase 146
5455 8298485 depth 36 187.82621693611145   163.09974765777588 increase 151
5600 8658368 depth 37 180.9691367149353   157.12904167175293 increase 145
5753 9007431 depth 38 183.04777336120605   159.00301218032837 increase 153
5917 9356391 depth 39 176.8722870349884   153.52902483940125 increase 164
6059 9700714 depth 40 177.86803460121155   154.48948502540588 increase 142
6213 10043408 depth 41 175.51527190208435   152.49061155319214 increase 154
6342 10384771 depth 42 173.6832926273346   150.674072265625 increase 129
6477 10723579 depth 43 173.49302339553833   150.84438800811768 increase 135
6617 11063474 depth 44 171.05049395561218   148.5886836051941 increase 140
6769 11399480 depth 45 172.69844436645508   150.1340548992157 increase 152
6911 11733579 depth 46 170.08466219902039   147.98799967765808 increase 142
7052 12043985 depth 47 159.36196565628052   138.2976474761963 increase 141
7182 12344486 depth 48 152.66902875900269   132.64966106414795 increase 130
7319 12634640 depth 49 149.83153796195984   130.2137849330902 increase 137
final_state_count:  7319
{'safe'}
1 not(A(G(safe)))
CTL formula satisfied: not(A(G(safe))) 1 0
number of counterexamplesï¼š 7196
iteration : 2 True 7196
refine: 0.5521719455718994 train: 72.75229072570801 construct kripke structure: 6230.0156416893005 model checking: 0.3115718364715576
2022-05-17-05_48_47
2022-05-17-05_48_47
[-4.8, -0.42, 4.8, 0.428]
number of all states in rtree 12327
cnt1 1000
cnt1 2000
cnt1 3000
cnt1 4000
cnt1 5000
cnt1 6000
cnt1 7000
--------- 7196 5131 28784
number of states after refinement: 33915
2022-05-17-05_48_49
episode= 50
avg reward: 9.78
episode= 100
avg reward: 9.64
episode= 150
avg reward: 9.74
episode= 200
avg reward: 10.08
episode= 250
avg reward: 9.72
episode= 300
avg reward: 9.56
episode= 350
avg reward: 9.52
episode= 400
avg reward: 9.74
episode= 450
avg reward: 9.48
episode= 500
avg reward: 9.34
episode= 550
avg reward: 9.56
episode= 600
avg reward: 9.64
episode= 650
avg reward: 11.48
episode= 700
avg reward: 68.98
episode= 750
avg reward: 176.1
episode= 800
avg reward: 188.98
episode= 850
avg reward: 309.64
episode= 900
avg reward: 237.2
episode= 950
avg reward: 241.12
episode= 1000
avg reward: 18.62
episode= 1050
avg reward: 55.26
episode= 1100
avg reward: 380.16
episode= 1150
avg reward: 471.28
episode= 1200
avg reward: 490.66
episode= 1250
avg reward: 226.26
episode= 1300
avg reward: 264.98
episode= 1350
avg reward: 147.76
episode= 1400
avg reward: 147.9
episode= 1450
avg reward: 151.66
episode= 1500
avg reward: 158.76
episode= 1550
avg reward: 182.54
episode= 1600
avg reward: 192.34
episode= 1650
avg reward: 190.12
episode= 1700
avg reward: 218.32
episode= 1750
avg reward: 166.88
episode= 1800
avg reward: 364.22
episode= 1850
avg reward: 394.8
episode= 1900
avg reward: 355.74
episode= 1950
avg reward: 498.24
episode= 2000
avg reward: 348.58
episode= 2050
avg reward: 434.66
episode= 2100
avg reward: 316.4
episode= 2150
avg reward: 423.18
episode= 2200
avg reward: 359.34
episode= 2250
avg reward: 332.86
episode= 2300
avg reward: 438.5
episode= 2350
avg reward: 343.86
episode= 2400
avg reward: 394.74
episode= 2450
avg reward: 500.0
0   evaluate total_reward 1000.0 0.13444897093213334 0.008445558978616737 1000
1   evaluate total_reward 1000.0 0.08866797847929708 0.03656251111628545 1000
2   evaluate total_reward 1000.0 0.0905242906995825 0.03603876205626979 1000
3   evaluate total_reward 1000.0 0.1643137229132062 0.026930780168257222 1000
4   evaluate total_reward 1000.0 0.11284144647278271 0.0317047745256787 1000
5   evaluate total_reward 1000.0 0.11063470268037358 0.0395777624213878 1000
6   evaluate total_reward 1000.0 0.06766661875789666 0.009684901219555616 1000
7   evaluate total_reward 1000.0 0.08948094455996512 0.03475247916565991 1000
8   evaluate total_reward 1000.0 0.11404982504390972 0.03526472126739408 1000
9   evaluate total_reward 1000.0 0.5298031976163107 0.03898694775435119 1000
training finished, episode= 2450
/home/TianJiaXu/RL2/abstract/cartpole/dqn0.pt loaded.
number of initial states: 1
9 37 depth 0 0.0009531974792480469   0.0007598400115966797 increase 8
26 205 depth 1 0.021242618560791016   0.01825261116027832 increase 17
45 930 depth 2 0.12432599067687988   0.10601139068603516 increase 19
80 2439 depth 3 0.41979050636291504   0.36371707916259766 increase 35
122 6128 depth 4 0.9593753814697266   0.826852560043335 increase 42
173 10147 depth 5 2.062110185623169   1.7956922054290771 increase 51
225 18146 depth 6 2.401214122772217   2.077482223510742 increase 52
288 26186 depth 7 4.485949277877808   3.904324531555176 increase 63
340 41013 depth 8 4.799147129058838   4.150372505187988 increase 52
442 55661 depth 9 8.593384504318237   7.457994699478149 increase 102
499 81072 depth 10 9.0149827003479   7.774886846542358 increase 57
614 104933 depth 11 14.78606128692627   12.829280138015747 increase 115
678 142447 depth 12 14.319449424743652   12.381378889083862 increase 64
784 179035 depth 13 20.942991256713867   18.18720555305481 increase 106
852 226623 depth 14 20.87974262237549   18.098849534988403 increase 68
960 274111 depth 15 26.56953716278076   23.10413408279419 increase 108
1033 332117 depth 16 27.19899034500122   23.58475160598755 increase 73
1156 392006 depth 17 33.34218955039978   28.93865728378296 increase 123
1237 460349 depth 18 35.089438676834106   30.40323805809021 increase 81
1353 532303 depth 19 40.56083154678345   35.08753848075867 increase 116
1458 609700 depth 20 42.630286693573   36.90435194969177 increase 105
1580 692160 depth 21 44.896883726119995   38.8938422203064 increase 122
1690 778399 depth 22 47.4910786151886   41.16623854637146 increase 110
1864 871000 depth 23 49.03299617767334   42.531327962875366 increase 174
1978 967360 depth 24 53.50753378868103   46.43212580680847 increase 114
2165 1071347 depth 25 55.2596378326416   47.90835189819336 increase 187
2297 1177202 depth 26 60.214101791381836   52.18316721916199 increase 132
2497 1293256 depth 27 60.35509157180786   52.24721312522888 increase 200
2650 1410048 depth 28 67.09602689743042   58.10140538215637 increase 153
2866 1538257 depth 29 67.69893598556519   58.57974433898926 increase 216
3050 1666132 depth 30 73.7403335571289   63.89754271507263 increase 184
3279 1801276 depth 31 73.962069272995   64.06007695198059 increase 229
3448 1935858 depth 32 77.28966784477234   67.0007975101471 increase 169
3695 2075159 depth 33 77.50164079666138   67.19551372528076 increase 247
3869 2215328 depth 34 79.4864752292633   68.88583421707153 increase 174
4109 2358489 depth 35 80.54227757453918   69.7257833480835 increase 240
4269 2502303 depth 36 81.7512354850769   70.83217334747314 increase 160
4524 2650204 depth 37 83.24533367156982   72.02178239822388 increase 255
4692 2797193 depth 38 84.74258470535278   73.33080220222473 increase 168
4958 2947871 depth 39 84.67159914970398   73.25957679748535 increase 266
5107 3096458 depth 40 86.5922110080719   74.97531414031982 increase 149
5366 3248900 depth 41 85.78186416625977   74.35986709594727 increase 259
5508 3398039 depth 42 87.36498546600342   75.69887733459473 increase 142
5774 3551615 depth 43 85.16233539581299   73.7542667388916 increase 266
5937 3702028 depth 44 88.06081342697144   76.351891040802 increase 163
6206 3857471 depth 45 86.01971077919006   74.47925591468811 increase 269
6387 4010323 depth 46 89.34299230575562   77.36271595954895 increase 181
6631 4167205 depth 47 88.20952725410461   76.47877287864685 increase 244
6820 4324552 depth 48 90.57654595375061   78.34573125839233 increase 189
7076 4487276 depth 49 90.60538244247437   78.47655272483826 increase 256
final_state_count:  7076
{'safe'}
1 not(A(G(safe)))
CTL formula not satisfied: not(A(G(safe))) 0 1
number of counterexamplesï¼š 0
iteration : 3 False 0
refine: 1.6415190696716309 train: 302.57986283302307 construct kripke structure: 2489.8613951206207 model checking: 0.3394482135772705
2022-05-17-06_35_21

Process finished with exit code 0
